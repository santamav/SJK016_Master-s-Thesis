{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG development  using SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing sbert transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub-0.25.1-py3.8.egg (from sentence-transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: filelock in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.68)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-10-05 16:41:46.701312: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-05 16:41:46.799005: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-05 16:41:47.429450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-05 16:41:50.001610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/vicentamen/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INDEXING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Mind2Web dataset form huggingface\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Text only dataset\n",
    "ds = load_dataset(\"osunlp/Mind2Web\")\n",
    "# Multimodal dataset\n",
    "#ds = load_dataset(\"osunlp/Multimodal-Mind2Web\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42254\n"
     ]
    }
   ],
   "source": [
    "# Extract the train split from the dataset\n",
    "train_ds = ds['train']\n",
    "\n",
    "# Get an example task for testing\n",
    "task = train_ds[1]\n",
    "# Get the HTML from one of the task's actions for testing\n",
    "html = task['actions'][0]['cleaned_html']\n",
    "print(len(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from HTML and parse it\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create a path with parent ids\n",
    "def create_path(node, path=''):\n",
    "    # Recursively build the path using 'backend_node_id' attributes\n",
    "    if not node or not node.has_attr('backend_node_id'):\n",
    "        return path\n",
    "    current_node_id = node['backend_node_id']\n",
    "    parent_path = create_path(node.parent, path)\n",
    "    return f\"{parent_path}/{current_node_id}\".lstrip('/')\n",
    "\n",
    "# Function to parse the HTML and extract paths and content\n",
    "def parse_html_for_rag(html_content):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # List to store parsed data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through all elements with 'backend_node_id'\n",
    "    for element in soup.find_all(attrs={\"backend_node_id\": True}):\n",
    "        # Create hierarchical path\n",
    "        path = create_path(element)\n",
    "        # Get the text content of the element\n",
    "        text = element.get_text(strip=True)\n",
    "        # Append to data list\n",
    "        data.append({\n",
    "            \"backend_node_id\": element[\"backend_node_id\"],\n",
    "            \"tag\": element.name,\n",
    "            \"text\": text,\n",
    "            \"path\": path\n",
    "        })\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# NOTE: We could clean the text further by removing special characters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    backend_node_id   tag                                               text  \\\n",
      "0               117  html  Skip to main contentUse Tock at your businessB...   \n",
      "1               561   div  Skip to main contentUse Tock at your businessB...   \n",
      "2               562   div  Skip to main contentUse Tock at your businessB...   \n",
      "3               569   div  Skip to main contentUse Tock at your businessB...   \n",
      "4               570   div  Skip to main contentUse Tock at your businessB...   \n",
      "..              ...   ...                                                ...   \n",
      "470            1422  text                                           Facebook   \n",
      "471            1424  span                                  Explore Tock 2023   \n",
      "472            1425  text                                  Explore Tock 2023   \n",
      "473            1511     a                                               null   \n",
      "474            1512  text                                               null   \n",
      "\n",
      "                                                  path  \n",
      "0                                                  117  \n",
      "1                                                  561  \n",
      "2                                              561/562  \n",
      "3                                          561/562/569  \n",
      "4                                      561/562/569/570  \n",
      "..                                                 ...  \n",
      "470  561/562/569/570/1348/1376/1377/1406/1419/1420/...  \n",
      "471                561/562/569/570/1348/1376/1377/1424  \n",
      "472           561/562/569/570/1348/1376/1377/1424/1425  \n",
      "473                                               1511  \n",
      "474                                          1511/1512  \n",
      "\n",
      "[475 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "parsed_task = parse_html_for_rag(html)\n",
    "print(parsed_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to create embeddings from HTML content dataframe\n",
    "def generate_html_embeddings(df, embedding_model):\n",
    "    # Combine the relevant text fields into a single string for embedding\n",
    "    df['text_combined'] = df.apply(lambda row: f\"{row['tag']} {row['path']} {row['text']}\", axis=1)\n",
    "    \n",
    "    # Generate embeddings for each combined text field\n",
    "    embeddings = embedding_model.encode(df['text_combined'].tolist(), convert_to_tensor=False)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = generate_html_embeddings(parsed_task.copy(), model)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book a winery tour in Napa Valley in a winery which serves Mediterranean cuisine with wine testing for 4 guests on April 15, 10 am in a outdoor setup.\n"
     ]
    }
   ],
   "source": [
    "# Extract the user prompt from the task\n",
    "# NOTE: \n",
    "#   1. We could use some pre-reasoning to include with the user prompt\n",
    "#   2. We should use some way to enrich the query with task information like the reasoning and the current step\n",
    "user_prompt = task['confirmed_task']\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt embeddings\n",
    "user_prompt_embedding = model.encode(user_prompt, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.2217e-01,  3.4749e-01,  3.3877e-01,  3.1184e-01,  3.2577e-01,\n",
      "          6.4265e-02, -2.2831e-02,  1.0293e-01,  4.4012e-02,  1.6536e-01,\n",
      "          4.6509e-03,  8.4426e-02, -4.6601e-03,  6.3669e-02,  5.5652e-02,\n",
      "          1.6974e-01,  1.6421e-01,  1.6076e-01,  9.3829e-02,  1.9727e-01,\n",
      "          1.9513e-01,  1.3535e-01,  1.9712e-01,  1.8766e-01,  1.3866e-01,\n",
      "         -1.8315e-02,  3.0039e-02,  7.9458e-03, -1.9339e-02,  3.8067e-02,\n",
      "          4.2775e-02, -3.1243e-02,  3.8221e-01,  3.7619e-01,  2.9068e-01,\n",
      "          1.3713e-01,  1.3352e-01,  1.2558e-01,  1.7823e-01,  8.9068e-02,\n",
      "          1.1478e-01,  2.7420e-03,  9.3036e-02, -9.6099e-03,  2.3148e-01,\n",
      "          2.3479e-01,  9.0501e-02,  1.8497e-01,  8.7875e-02,  1.1716e-01,\n",
      "          1.0222e-01,  1.9760e-01,  9.6374e-02,  1.0586e-01,  8.0904e-03,\n",
      "          1.4517e-01,  5.0066e-02,  1.3921e-01,  5.5587e-02,  3.8763e-01,\n",
      "          2.5408e-01,  8.6707e-02, -2.3203e-02,  1.8426e-02,  1.3860e-01,\n",
      "          1.2995e-02, -1.6357e-02, -2.8380e-02, -2.4439e-02,  4.7372e-02,\n",
      "          2.1567e-02,  4.0836e-02,  2.9768e-02,  1.6309e-01,  3.0432e-02,\n",
      "         -7.3468e-03, -3.2560e-02,  4.1436e-02,  1.0710e-01,  1.4522e-01,\n",
      "          2.7665e-02,  9.9593e-02,  8.1086e-02,  7.2790e-02, -1.7991e-02,\n",
      "          1.5073e-01,  3.9454e-02,  1.3561e-01,  4.2081e-02,  1.3094e-01,\n",
      "          2.2067e-02,  1.3145e-01,  3.8979e-02,  1.2981e-01,  3.3694e-02,\n",
      "          1.3504e-01,  4.1786e-02,  1.2991e-01,  3.5521e-02,  1.3652e-01,\n",
      "          3.5323e-02,  1.3449e-01,  3.6069e-02,  1.3763e-01,  3.9297e-02,\n",
      "          1.3281e-01,  3.4024e-02,  1.3574e-01,  3.8660e-02,  1.3387e-01,\n",
      "          1.0669e-02,  1.3537e-01,  4.0969e-02,  1.3407e-01,  3.5002e-02,\n",
      "          1.3491e-01,  3.9926e-02,  1.2966e-01,  3.2750e-02,  1.3336e-01,\n",
      "          3.6038e-02,  1.2708e-01,  2.6386e-02,  1.3124e-01,  3.1076e-02,\n",
      "          1.2725e-01,  2.6590e-02,  1.2717e-01,  2.6223e-02,  1.2165e-01,\n",
      "          1.8100e-02,  1.3432e-01,  2.9435e-02,  1.3123e-01,  3.2985e-02,\n",
      "          1.3894e-01,  1.8945e-01,  8.5055e-02,  1.0904e-01,  1.6076e-01,\n",
      "          2.0516e-01,  9.7794e-02,  2.3081e-01,  1.3190e-01,  2.3039e-01,\n",
      "          1.3017e-01,  2.3251e-01,  1.3095e-01,  2.3069e-01,  1.3172e-01,\n",
      "          2.3404e-01,  1.3183e-01,  2.2786e-01,  1.2330e-01,  2.3281e-01,\n",
      "          1.2932e-01,  2.2736e-01,  1.2748e-01,  2.3194e-01,  1.2791e-01,\n",
      "          1.0390e-01,  3.1259e-02,  1.3939e-03,  6.7521e-02,  9.2145e-02,\n",
      "          4.4961e-02,  1.4919e-01,  1.6324e-01,  1.0546e-01, -1.5136e-02,\n",
      "          1.9301e-01,  1.1201e-01,  5.7124e-02,  1.2110e-02, -1.3007e-02,\n",
      "          8.4206e-02,  1.2402e-02,  1.1119e-01,  6.5457e-02, -1.6442e-02,\n",
      "          1.3974e-01,  5.4373e-02,  1.1131e-01,  4.2254e-02, -1.9711e-02,\n",
      "          1.1774e-01,  4.1492e-02,  3.2425e-01,  2.6721e-01, -3.4321e-02,\n",
      "          3.6815e-01,  2.5821e-01,  3.2102e-01,  3.2542e-01,  7.8727e-03,\n",
      "          2.7591e-02,  4.9193e-02,  3.0582e-03, -2.8720e-02,  1.4600e-02,\n",
      "         -5.1557e-02,  1.1570e-01,  3.3198e-02, -5.4355e-03,  1.6100e-01,\n",
      "          6.6033e-02,  3.2154e-02,  3.3316e-01,  3.4320e-01,  3.4206e-01,\n",
      "          2.2756e-01,  2.4976e-01, -4.2802e-02,  2.3124e-01,  5.9190e-02,\n",
      "          2.9690e-04,  2.6240e-01,  2.2528e-01,  7.1792e-02,  1.9364e-01,\n",
      "          2.2234e-01, -3.7655e-02,  1.7811e-01,  8.5537e-02,  2.6237e-02,\n",
      "          1.7411e-01,  5.1155e-02,  9.0518e-02,  1.7955e-01,  2.0565e-01,\n",
      "         -4.6138e-02,  1.8089e-01,  1.6012e-01,  9.7147e-02,  9.6030e-02,\n",
      "          2.6050e-02,  3.8335e-03,  3.1759e-01,  3.3117e-01, -4.4536e-02,\n",
      "          3.1477e-01,  9.0547e-02,  5.1457e-02,  2.9927e-01,  8.7318e-02,\n",
      "          2.0320e-01,  2.3617e-01,  2.8088e-01, -4.3491e-02,  2.5327e-01,\n",
      "          1.8097e-01,  9.9382e-02,  1.4360e-01,  7.4620e-02, -3.1609e-02,\n",
      "          9.0603e-02,  8.3974e-02, -5.1488e-02,  6.3026e-02,  5.9025e-02,\n",
      "          1.1879e-02,  1.3627e-01,  3.7662e-02,  1.8121e-02,  2.4098e-01,\n",
      "          2.5148e-01, -2.9577e-02,  2.1915e-01,  1.2638e-01,  6.4494e-02,\n",
      "          1.3273e-01,  5.3509e-02, -2.6501e-02,  8.6658e-02,  1.0354e-01,\n",
      "         -5.7086e-02,  7.9773e-02,  6.6104e-03, -1.7803e-02,  9.8341e-02,\n",
      "          1.1756e-02, -2.6687e-02,  7.4165e-02,  5.0492e-02, -3.3445e-03,\n",
      "          1.9038e-01,  1.9238e-01,  1.8701e-01,  1.8355e-01,  1.7655e-01,\n",
      "          8.7088e-02,  1.1777e-01,  4.8604e-02,  7.6865e-02,  2.5010e-02,\n",
      "          1.8396e-01,  1.8952e-01,  7.6510e-02,  6.4157e-02,  1.5101e-01,\n",
      "          7.4404e-02,  3.5517e-02,  6.3939e-02,  6.1325e-02,  5.9466e-02,\n",
      "          1.1502e-01,  3.2923e-02, -1.9063e-02,  8.6518e-02,  2.0113e-01,\n",
      "          8.7901e-02,  1.4042e-01,  5.6382e-02,  1.6344e-02,  1.5460e-01,\n",
      "          7.0437e-02,  3.2464e-02,  6.5282e-02,  5.8145e-02,  2.0186e-03,\n",
      "          1.5430e-01,  1.4406e-01,  1.3762e-01,  1.9176e-01,  1.8732e-01,\n",
      "          2.0073e-01,  8.9450e-02,  4.9734e-02,  5.1320e-02,  9.5315e-02,\n",
      "          6.1498e-02,  3.5083e-01,  2.6490e-01,  1.5154e-01,  9.8798e-02,\n",
      "          5.8632e-02,  1.1399e-01,  1.0019e-01,  1.0450e-01, -2.1049e-02,\n",
      "         -4.9190e-02,  2.2933e-01,  2.1070e-01,  8.3052e-02,  7.9779e-03,\n",
      "         -2.6007e-02,  3.1100e-01,  2.9568e-01,  3.2637e-01,  3.9120e-01,\n",
      "          3.9611e-01,  3.3183e-01,  1.0749e-01,  1.7991e-01,  8.6325e-02,\n",
      "          1.6809e-01,  5.5147e-02,  3.0173e-02,  1.7539e-01,  7.0524e-02,\n",
      "          4.6170e-02,  6.8060e-02,  5.6468e-02, -2.2096e-03,  2.5351e-01,\n",
      "          2.5002e-01,  2.4372e-01,  2.3878e-01,  2.4529e-01,  1.3146e-01,\n",
      "          1.6731e-01,  1.6091e-01, -3.9951e-03, -1.9476e-02, -3.1723e-02,\n",
      "         -3.6671e-03,  1.2689e-01,  1.6351e-01,  1.0249e-01,  9.5522e-02,\n",
      "         -6.7817e-04, -1.3746e-02,  1.1360e-01,  9.9709e-02,  1.0093e-01,\n",
      "          1.6558e-01,  1.3678e-02, -2.5371e-02,  1.3628e-01,  2.3444e-01,\n",
      "          1.3456e-01,  1.1727e-01,  2.6506e-02,  9.9803e-03,  1.4481e-01,\n",
      "          4.9329e-02,  2.1274e-02,  4.0745e-02,  2.7334e-02, -2.9064e-02,\n",
      "         -1.6388e-02, -2.3110e-02,  1.1960e-03, -3.3456e-02,  5.2938e-02,\n",
      "          4.4427e-02, -1.7667e-02,  1.2338e-01,  1.5019e-01,  1.4095e-01,\n",
      "          1.3789e-01,  1.9960e-01,  9.9340e-02,  5.4532e-02,  3.3571e-01,\n",
      "          2.7193e-01,  9.6002e-02, -4.8760e-03, -6.4350e-04, -5.7276e-03,\n",
      "         -5.4942e-02,  2.9742e-02, -9.7412e-03,  5.7672e-02, -2.7312e-02,\n",
      "          7.5559e-02,  8.3727e-02,  3.0457e-02,  1.3704e-01,  7.4667e-02,\n",
      "          1.1050e-01,  1.4734e-02, -8.0486e-03, -1.8571e-02,  7.0119e-02,\n",
      "          7.5112e-03, -2.7966e-02,  1.0284e-02,  1.2451e-02,  6.2691e-02,\n",
      "          2.0841e-02, -7.2480e-03,  8.5869e-02,  1.0933e-01,  5.5630e-02,\n",
      "          2.5751e-02,  1.9557e-02,  4.8669e-02,  1.7108e-02, -1.4410e-02,\n",
      "          1.9953e-02,  4.7724e-02, -1.7816e-02, -3.7507e-02,  1.7470e-02,\n",
      "          3.5764e-02,  6.5850e-02, -1.0140e-03, -1.9486e-02,  4.9642e-02,\n",
      "          8.3304e-02,  1.4140e-02, -5.4996e-03,  5.2470e-02,  7.0018e-02,\n",
      "          1.2705e-02, -1.3375e-02,  6.2175e-02,  9.6048e-02,  2.2318e-02,\n",
      "          2.4436e-03,  6.0587e-02,  4.0791e-02,  1.8286e-02, -4.6101e-03]])\n"
     ]
    }
   ],
   "source": [
    "# Get similarities\n",
    "similarities = model.similarity(user_prompt_embedding, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores: [[0.39611417 0.39119527 0.38763046 0.38220945 0.37618726]]\n",
      "Top indices: [[350 349  59  32  33]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "top_values, top_indices = tf.math.top_k(similarities, k=5)\n",
    "\n",
    "print(\"Similarity scores:\", top_values.numpy())\n",
    "print(\"Top indices:\", top_indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most relevant elements:\n",
      "\n",
      "backend_node_id     tag                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text                                                path\n",
      "           1162      h2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Wineries & Tasting Rooms    561/562/569/570/647/648/1158/1159/1160/1161/1162\n",
      "           1161 section                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Wineries & Tasting RoomsTaste your way through varietals & vintagesExplore all         561/562/569/570/647/648/1158/1159/1160/1161\n",
      "            717  option                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Wineries 561/562/569/570/647/648/649/663/664/665/668/708/717\n",
      "            647    main DELICIOUSSTARTSHERE.Reservation typeDine inPickupDeliveryEventsWineriesEverythingLocationDateTimeNow11:30 AM12:00 PM12:30 PM1:00 PM1:30 PM2:00 PM2:30 PM3:00 PM3:30 PM4:00 PM4:30 PM5:00 PM5:30 PM6:00 PM6:30 PM7:00 PM7:30 PM8:00 PM8:30 PM9:00 PM9:30 PM10:00 PM10:30 PM11:00 PM11:30 PMParty size1 guest2 guests3 guests4 guests5 guests6 guests7 guests8 guests9 guests10 guestsSearchExplore all that Tock has to offerDine inPickupDeliveryEventsWineriesNew & NotableThe latest & greatest on TockExplore allExplore allAgniColumbus, OH - Brewery DistrictGrillStreetside 62 BistroWashington Court House, OHRestaurantHell's Backbone Grill & FarmBoulder, UTFour Corners Farm To TableSymposiumCincinnati, OH - East Walnut HIllsWine ShopThe Merchant TavernAkron, OH - Merriman ValleyAmericanLuigi's Ristorante ItalianoMason, OHItalianUrban Grill on MainCincinnati, OH - Village of NewtownAmericanThe Pickle and PigOxford, OH - Mile SquareAmericanView AllWomen'sHistory MonthCelebrating and supporting leading womenshaking up the industry.Explore nowTock To GoPickup and delivery mealsExplore allExplore allView AllTock Gift CardsGive the deliciousgift of Tock.Share your love of great food and wine. For every occasion. Any amount. Never expires. Sure to delight.Send a gift cardThe Tock BlogChef Interviews, Stories, & Curated City Guides.Read the latestWineries & Tasting RoomsTaste your way through varietals & vintagesExplore allExplore allView AllReservations. Events. To-Go.TheOnlyAll In One Solution.Tock is here to meet the ever-changing needs of hospitality.Learn moreChase Cardmember TablesPrimetime reservations at restaurants across the countryExplore allExplore allView AllBrowse all of TockLoad more                                 561/562/569/570/647\n",
      "            648     div DELICIOUSSTARTSHERE.Reservation typeDine inPickupDeliveryEventsWineriesEverythingLocationDateTimeNow11:30 AM12:00 PM12:30 PM1:00 PM1:30 PM2:00 PM2:30 PM3:00 PM3:30 PM4:00 PM4:30 PM5:00 PM5:30 PM6:00 PM6:30 PM7:00 PM7:30 PM8:00 PM8:30 PM9:00 PM9:30 PM10:00 PM10:30 PM11:00 PM11:30 PMParty size1 guest2 guests3 guests4 guests5 guests6 guests7 guests8 guests9 guests10 guestsSearchExplore all that Tock has to offerDine inPickupDeliveryEventsWineriesNew & NotableThe latest & greatest on TockExplore allExplore allAgniColumbus, OH - Brewery DistrictGrillStreetside 62 BistroWashington Court House, OHRestaurantHell's Backbone Grill & FarmBoulder, UTFour Corners Farm To TableSymposiumCincinnati, OH - East Walnut HIllsWine ShopThe Merchant TavernAkron, OH - Merriman ValleyAmericanLuigi's Ristorante ItalianoMason, OHItalianUrban Grill on MainCincinnati, OH - Village of NewtownAmericanThe Pickle and PigOxford, OH - Mile SquareAmericanView AllWomen'sHistory MonthCelebrating and supporting leading womenshaking up the industry.Explore nowTock To GoPickup and delivery mealsExplore allExplore allView AllTock Gift CardsGive the deliciousgift of Tock.Share your love of great food and wine. For every occasion. Any amount. Never expires. Sure to delight.Send a gift cardThe Tock BlogChef Interviews, Stories, & Curated City Guides.Read the latestWineries & Tasting RoomsTaste your way through varietals & vintagesExplore allExplore allView AllReservations. Events. To-Go.TheOnlyAll In One Solution.Tock is here to meet the ever-changing needs of hospitality.Learn moreChase Cardmember TablesPrimetime reservations at restaurants across the countryExplore allExplore allView AllBrowse all of TockLoad more                             561/562/569/570/647/648\n"
     ]
    }
   ],
   "source": [
    "indexes = top_indices.numpy()\n",
    "\n",
    "print (\"Top 5 most relevant elements:\\n\")\n",
    "for i in indexes:\n",
    "    print(parsed_task.iloc[i].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'attributes': '{\"backend_node_id\": \"110\", \"bounding_box_rect\": \"557.671875,634.390625,24,24\", \"class\": \"MuiSvgIcon-root css-tdzr9e\", \"data_pw_testid_buckeye_candidate\": \"1\"}', 'backend_node_id': '110', 'is_original_target': True, 'is_top_level_target': True, 'tag': 'svg'}]\n"
     ]
    }
   ],
   "source": [
    "print(task['actions'][0]['pos_candidates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend_node_id tag text                                                    path\n",
      "            110 svg      561/562/569/570/647/648/649/663/664/722/725/727/728/110\n"
     ]
    }
   ],
   "source": [
    "# Find rows where the 'path' column contains the specified value\n",
    "path_value = \"110\"\n",
    "result = parsed_task[parsed_task['path'].str.contains(path_value)]\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
